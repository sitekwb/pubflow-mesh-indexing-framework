{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, classes):\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor(data, dtype=torch.float)\n",
    "        self.classes = torch.tensor(classes, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i], self.classes[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_path: str, train_classes_path: str, test_path: str, test_classes_path: str,\n",
    "                 batch_size: int = 1):\n",
    "        super().__init__()\n",
    "        self.train_path = train_path\n",
    "        self.train_classes_path = train_classes_path\n",
    "        self.test_path = test_path\n",
    "        self.test_classes_path = test_classes_path\n",
    "\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.train_classes = None\n",
    "        self.test_classes = None\n",
    "        self.sep = ';'\n",
    "        self.num_classes = None\n",
    "        self.batch_size = batch_size\n",
    "        self.vector_len = None\n",
    "\n",
    "        self.prepare_data()\n",
    "\n",
    "    @staticmethod\n",
    "    def pad(text_tensor, total):\n",
    "        n = total - len(text_tensor)\n",
    "        return F.pad(text_tensor, (0, n))\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.download_dataset()\n",
    "        self.num_classes = len(set(self.train_classes))\n",
    "\n",
    "    def download_dataset(self):\n",
    "        with open(self.train_path) as f:\n",
    "            self.train_data = [[float(_) for _ in line.split(self.sep)] for line in f]\n",
    "        with open(self.test_path) as f:\n",
    "            self.test_data = [[float(_) for _ in line.split(self.sep)] for line in f]\n",
    "        with open(self.train_classes_path) as f:\n",
    "            self.train_classes = [int(line) - 1 for line in f]\n",
    "        with open(self.test_classes_path) as f:\n",
    "            self.test_classes = [int(line) - 1 for line in f]\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        self.vector_len = self.count_vector_len()\n",
    "        self.train_data = [i + [0] * (self.vector_len - len(i)) for i in self.train_data]\n",
    "        self.test_data = [i + [0] * (self.vector_len - len(i)) for i in\n",
    "                          list(map(lambda vector: vector[:self.vector_len], self.test_data))]\n",
    "        self.train_dataset = MyDataset(data=self.train_data, classes=self.train_classes)\n",
    "        self.test_dataset = MyDataset(data=self.test_data, classes=self.test_classes)\n",
    "\n",
    "    def count_vector_len(self):\n",
    "        max_len = 0\n",
    "        for vector in self.train_data:\n",
    "            max_len = max(max_len, len(vector))\n",
    "        return max_len\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    @property\n",
    "    def num_inputs(self):\n",
    "        if not self.vector_len:\n",
    "            self.vector_len = self.count_vector_len()\n",
    "        return self.vector_len\n",
    "\n",
    "    @property\n",
    "    def num_outputs(self):\n",
    "        return self.num_classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from typing import Optional\n",
    "from tqdm import tqdm\n",
    "et = ET.parse('/home/wojtek/Documents/Indexing/desc2022.xml')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_text(node):\n",
    "    try:\n",
    "        return node.text\n",
    "    except AttributeError:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "Value = str\n",
    "\n",
    "\n",
    "class MeSHTree:\n",
    "    def __init__(self, value: Optional[str] = None, descriptor_name: Optional[str] = None, tree_number: Optional[str] = None):\n",
    "        self.children_nodes: List[MeSHTree] = []\n",
    "        self.value: Optional[Value] = value\n",
    "        self.descriptor_name: Optional[str] = descriptor_name\n",
    "        self.tree_number: Optional[str] = tree_number\n",
    "\n",
    "    def get_or_create_child(self, child_value: Value, descriptor_name: Optional[str] = None, tree_number: Optional[str] = None):\n",
    "        for child_tree in self.children_nodes:\n",
    "            if child_tree.value == child_value:\n",
    "                return child_tree\n",
    "        new_tree = MeSHTree(child_value, descriptor_name, tree_number)\n",
    "        self.children_nodes.append(new_tree)\n",
    "        return new_tree\n",
    "\n",
    "    def __str__(self):\n",
    "        ret = self.value if self.value else '-'\n",
    "        for node in self.children_nodes:\n",
    "            ret += f\" {node}\"\n",
    "        ret += ' |'\n",
    "        return ret\n",
    "\n",
    "    def build_from_ids(self, tree_str: str, descriptor_name: Optional[str] = None):\n",
    "        top_term = tree_str[0]\n",
    "        nodes = tree_str[1:].split('.')\n",
    "        tmp_node = self.get_or_create_child(top_term)\n",
    "        for node_str in nodes:\n",
    "            tmp_node = tmp_node.get_or_create_child(node_str)\n",
    "        tmp_node.descriptor_name = descriptor_name\n",
    "        tmp_node.tree_number = tree_str\n",
    "\n",
    "    def size(self):\n",
    "        if len(self.children_nodes) == 0:\n",
    "            return 0\n",
    "        size = 1\n",
    "        for child in self.children_nodes:\n",
    "            size += child.size()\n",
    "        return size\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return len(self.children_nodes) == 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield self\n",
    "        for child in self.children_nodes:\n",
    "            for sub_child in child:\n",
    "                yield sub_child\n",
    "\n",
    "    def iter_without_leafs(self):\n",
    "        for node in self:\n",
    "            if not node.is_leaf():\n",
    "                yield node"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- A 12 15 18 | | 19 2 | | | | B 13 85 14 | | | | |\n",
      "['None', 'A', '12', '15', '19', 'B', '13', '85']\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE\n",
    "tree = MeSHTree()\n",
    "\n",
    "tree_identifiers = ['A12.15.18', 'B13.85.14', 'A12.19.2']\n",
    "for tree_str in tree_identifiers:\n",
    "    top_term = tree_str[0]\n",
    "    nodes = tree_str[1:].split('.')\n",
    "    tmp_node = tree.get_or_create_child(top_term)\n",
    "    for node_str in nodes:\n",
    "        tmp_node = tmp_node.get_or_create_child(node_str)\n",
    "\n",
    "#   A - 12 - 15 - 18\n",
    "# - |      |\n",
    "#   |      - 19 - 2\n",
    "#   |\n",
    "#   B - 13 - 85 - 14\n",
    "\n",
    "print(tree)\n",
    "print([str(_.value) for _ in tree.iter_without_leafs()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30194/30194 [00:00<00:00, 65469.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "root = et.getroot()\n",
    "tree = MeSHTree()\n",
    "\n",
    "for record in tqdm(root.findall('DescriptorRecord')):\n",
    "    descriptor_name = get_text(record.find('DescriptorName/String'))\n",
    "    for tree_number_node in record.findall('TreeNumberList/TreeNumber'):\n",
    "        tree.build_from_ids(get_text(tree_number_node), descriptor_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "17262"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([_ for _ in tree.iter_without_leafs()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62334it [00:00, 809606.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None None\n",
      "None D None\n",
      "None J None\n",
      "None L None\n",
      "None A None\n",
      "None C None\n",
      "None B None\n",
      "None G None\n",
      "None N None\n",
      "None M None\n",
      "None I None\n",
      "None E None\n",
      "None F None\n",
      "None H None\n",
      "None K None\n",
      "None V None\n",
      "None Z None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# EMPTY DESCRIPTORS\n",
    "i = 0\n",
    "for node in tqdm(tree):\n",
    "    if not node.descriptor_name:\n",
    "        print(node.tree_number, node.value, node.descriptor_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# histogram of number of children\n",
    "numbers_of_children = []\n",
    "for node in tree:\n",
    "    numbers_of_children.append(len(node.children_nodes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([1.7006e+04, 2.1400e+02, 2.9000e+01, 9.0000e+00, 4.0000e+00]),\n array([  1. ,  21.8,  42.6,  63.4,  84.2, 105. ]),\n <BarContainer object of 5 artists>)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.hist(numbers_of_children, bins=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "17262"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numbers_of_children)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "numbers_of_children = [value for value in numbers_of_children if value != 0.0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins = np.histogram(numbers_of_children, bins=15)\n",
    "logbins = np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins))\n",
    "plt.hist(numbers_of_children, bins=logbins)\n",
    "plt.xscale('log')\n",
    "plt.show()\n",
    "None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([51672,  5661,  1306,  1506,   448,   513,   209,   285,   155,\n           77,   105,    38,    79,    23,    55,    31,    20,    29,\n           11,    18,     7,    13,     7,     5,    10,     2,     6,\n            2,     5,     8,     2,     1,     0,     4,     0,     4,\n            1,     1,     1,     0,     2,     1,     0,     0,     0,\n            0,     0,     2,     1,     1,     0,     2,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     1,     1,\n            0,     0,     0,     2]),\n array([  0.        ,   1.56716418,   3.13432836,   4.70149254,\n          6.26865672,   7.8358209 ,   9.40298507,  10.97014925,\n         12.53731343,  14.10447761,  15.67164179,  17.23880597,\n         18.80597015,  20.37313433,  21.94029851,  23.50746269,\n         25.07462687,  26.64179104,  28.20895522,  29.7761194 ,\n         31.34328358,  32.91044776,  34.47761194,  36.04477612,\n         37.6119403 ,  39.17910448,  40.74626866,  42.31343284,\n         43.88059701,  45.44776119,  47.01492537,  48.58208955,\n         50.14925373,  51.71641791,  53.28358209,  54.85074627,\n         56.41791045,  57.98507463,  59.55223881,  61.11940299,\n         62.68656716,  64.25373134,  65.82089552,  67.3880597 ,\n         68.95522388,  70.52238806,  72.08955224,  73.65671642,\n         75.2238806 ,  76.79104478,  78.35820896,  79.92537313,\n         81.49253731,  83.05970149,  84.62686567,  86.19402985,\n         87.76119403,  89.32835821,  90.89552239,  92.46268657,\n         94.02985075,  95.59701493,  97.1641791 ,  98.73134328,\n        100.29850746, 101.86567164, 103.43283582, 105.        ]))"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.histogram(numbers_of_children, bins=len(set(numbers_of_children)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CascadeMeSH(pl.LightningModule):\n",
    "    def __init__(self, mesh_tree: MeSHTree):\n",
    "        super().__init__()\n",
    "        self.mesh_tree = mesh_tree\n",
    "        self.classifiers: Dict[Optional[str], nn.Sequential] = {}\n",
    "        for node in mesh_tree.iter_without_leafs():\n",
    "            self.classifiers[node.tree_number] = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(32 * 32 * 3, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, len(node.children_nodes) + 1),\n",
    "                nn.Threshold(0.7, 0.0)\n",
    "            )\n",
    "        # Initialize layers\n",
    "        self.loss_fct = F.cross_entropy\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.test_accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        clfs = [[self.classifiers.get(None)]] * x.size(0)\n",
    "        labels = [[]] * x.size(0)\n",
    "        tree = self.mesh_tree\n",
    "        stop = False\n",
    "        while not stop:\n",
    "            preds = torch.tensor([[clf(xi) for clf in my_clfs] for my_clfs, xi in zip(clfs, x)])\n",
    "            # new indices\n",
    "            all_indices = []\n",
    "            for x_index, pred in enumerate(preds):\n",
    "                for my_pred in pred:\n",
    "                    indices = []\n",
    "                    for i, indicator in enumerate(my_pred):\n",
    "                        if indicator > 0:\n",
    "                            if i == 0:\n",
    "                                # add to labels\n",
    "                                label = None # todo extract label from tree\n",
    "                                labels[x_index].append(label)\n",
    "                            indices.append(i)\n",
    "                # new labels\n",
    "\n",
    "            # new clfs\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx, mem1=None):\n",
    "        if not mem1:\n",
    "            mem1 = self.mem1\n",
    "        x, y = batch\n",
    "        cur, mem1_after = self.forward(x, mem1)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.train_accuracy(cur, y)\n",
    "        self.log(\"train_acc\", self.train_accuracy.compute(), prog_bar=True)\n",
    "        return {'loss': loss, 'mem1': mem1_after}\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     x, y = batch\n",
    "    #     spk, mem = self.forward(x)\n",
    "    #     loss = self.loss_fct(mem, y)\n",
    "    #     self.log(\"val_loss\", loss, prog_bar=True)\n",
    "    #     return {'loss': loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx, mem1=None):\n",
    "        if not mem1:\n",
    "            mem1 = self.mem1\n",
    "        x, y = batch\n",
    "        cur, mem1_after = self.forward(x, mem1)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.test_accuracy(cur, y)\n",
    "        self.log(\"test_acc\", self.test_accuracy.compute(), prog_bar=True)\n",
    "        return {'loss': loss, 'mem1': mem1_after}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "ib_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TrainTitleIB.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TestTitleIB.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TrainTitleIBClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TestTitleIBClass.csv'\n",
    ")\n",
    "b_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TrainTitleB.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TestTitleB.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TrainTitleBClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TestTitleBClass.csv'\n",
    ")\n",
    "ng_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TrainShortBydate.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TestShortBydate.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TrainShortBydateClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TestShortBydateClass.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "model_ng = SpikeText(num_inputs=ng_data_module.num_inputs, num_hidden=1000, beta=0.85,\n",
    "                     num_outputs=ng_data_module.num_outputs, learning_rate=1e-4)\n",
    "model_ib = SpikeText(num_inputs=ib_data_module.num_inputs, num_hidden=1000, beta=0.85,\n",
    "                     num_outputs=ib_data_module.num_outputs, learning_rate=1e-4)\n",
    "model_b = SpikeText(num_inputs=b_data_module.num_inputs, num_hidden=1000, beta=0.85,\n",
    "                    num_outputs=b_data_module.num_outputs, learning_rate=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"train_acc\",\n",
    "    dirpath='lightning_logs',\n",
    "    filename=\"{epoch:02d}-{train_acc:.2f}\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "ib_trainer = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                        max_epochs=1, gpus=torch.cuda.device_count(),\n",
    "                        callbacks=[checkpoint_callback])\n",
    "b_trainer = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                       max_epochs=1, gpus=torch.cuda.device_count(),\n",
    "                       callbacks=[checkpoint_callback])\n",
    "ng_trainer = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                        max_epochs=1, gpus=torch.cuda.device_count(),\n",
    "                        callbacks=[checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 752 K \n",
      "1 | lif1           | Leaky    | 0     \n",
      "2 | fc2            | Linear   | 20.0 K\n",
      "3 | train_accuracy | Accuracy | 0     \n",
      "4 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "772 K     Trainable params\n",
      "0         Non-trainable params\n",
      "772 K     Total params\n",
      "3.088     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e5d3b3ea609486785003f7a6c948fb5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | lif1           | Leaky    | 0     \n",
      "2 | fc2            | Linear   | 15.0 K\n",
      "3 | train_accuracy | Accuracy | 0     \n",
      "4 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa6d136914364e47a2031e35dbd6e4ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | lif1           | Leaky    | 0     \n",
      "2 | fc2            | Linear   | 15.0 K\n",
      "3 | train_accuracy | Accuracy | 0     \n",
      "4 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42d8e557b91744208ea11789165a02d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_sets = [(model_ng, ng_data_module, ng_trainer), (model_b, b_data_module, b_trainer),\n",
    "                 (model_ib, ib_data_module, ib_trainer)]\n",
    "for model, data_module, trainer in training_sets:\n",
    "    trainer.fit(model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cf15cf5b5f24c0aae1323fcd09da0d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.08134832233190536, 'test_loss': 4.655596733093262}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcbb80f6b6bf48da97e827abfba928f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3523232638835907, 'test_loss': 2.026945114135742}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b22b477a0e0d452dadea89dd433a193d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3480547368526459, 'test_loss': 2.051805257797241}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model, data_module, trainer in training_sets:\n",
    "    trainer.test(model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "class Perceptron(pl.LightningModule):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, learning_rate):\n",
    "        super().__init__()\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lr = learning_rate\n",
    "        self.loss_fct = F.cross_entropy\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.test_accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        cur1 = self.fc1(x)\n",
    "        cur2 = self.fc2(cur1)\n",
    "        return cur2\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        cur = self.forward(x)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.train_accuracy(cur, y)\n",
    "        self.log(\"train_acc\", self.train_accuracy.compute(), prog_bar=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        cur = self.forward(x)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.test_accuracy(cur, y)\n",
    "        self.log(\"test_acc\", self.test_accuracy.compute(), prog_bar=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "ib_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TrainTitleIB.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TestTitleIB.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TrainTitleIBClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TestTitleIBClass.csv'\n",
    ")\n",
    "b_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TrainTitleB.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TestTitleB.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TrainTitleBClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TestTitleBClass.csv'\n",
    ")\n",
    "ng_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TrainShortBydate.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TestShortBydate.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TrainShortBydateClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TestShortBydateClass.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 752 K \n",
      "1 | fc2            | Linear   | 20.0 K\n",
      "2 | train_accuracy | Accuracy | 0     \n",
      "3 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "772 K     Trainable params\n",
      "0         Non-trainable params\n",
      "772 K     Total params\n",
      "3.088     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41c132f107f34689ad5c9e18773989b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2dbde116ed474a9fa1e9692cba7f50d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.006094762589782476, 'test_loss': 4.882161617279053}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | fc2            | Linear   | 15.0 K\n",
      "2 | train_accuracy | Accuracy | 0     \n",
      "3 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65a71235214e44f3af35baa46b24d413"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "320811e37de446ce957f2cae5e8d673e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3267398178577423, 'test_loss': 2.287667751312256}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | fc2            | Linear   | 15.0 K\n",
      "2 | train_accuracy | Accuracy | 0     \n",
      "3 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83abbffedd164ca1a5d2beb15f1b7052"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:897: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ff46252e755417087aee3f822bfc3e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.36403772234916687, 'test_loss': 2.2534267902374268}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ng_mlp_model = Perceptron(num_inputs=ng_data_module.num_inputs, num_hidden=1000,\n",
    "                          num_outputs=ng_data_module.num_outputs, learning_rate=1e-4)\n",
    "ib_mlp_model = Perceptron(num_inputs=ib_data_module.num_inputs, num_hidden=1000,\n",
    "                          num_outputs=ib_data_module.num_outputs, learning_rate=1e-4)\n",
    "b_mlp_model = Perceptron(num_inputs=b_data_module.num_inputs, num_hidden=1000,\n",
    "                         num_outputs=b_data_module.num_outputs, learning_rate=1e-4)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"train_acc\",\n",
    "    dirpath='lightning_logs',\n",
    "    filename=\"{epoch:02d}-{train_acc:.2f}\",\n",
    ")\n",
    "mlp_trainer_ib = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                            max_epochs=5, gpus=torch.cuda.device_count(),\n",
    "                            callbacks=[checkpoint_callback])\n",
    "mlp_trainer_b = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                           max_epochs=5, gpus=torch.cuda.device_count(),\n",
    "                           callbacks=[checkpoint_callback])\n",
    "mlp_trainer_ng = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                            max_epochs=5, gpus=torch.cuda.device_count(),\n",
    "                            callbacks=[checkpoint_callback])\n",
    "\n",
    "mlp_training_sets = [(ng_mlp_model, ng_data_module, mlp_trainer_ng), (ib_mlp_model, ib_data_module, mlp_trainer_ib),\n",
    "                     (b_mlp_model, b_data_module, mlp_trainer_b)]\n",
    "\n",
    "for mlp_model, mlp_data_module, mlp_trainer in mlp_training_sets:\n",
    "    mlp_trainer.fit(mlp_model, datamodule=mlp_data_module)\n",
    "    mlp_trainer.test(mlp_model, datamodule=mlp_data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7532, 751]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-93-5d592bc390d1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"RESULT:\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0maccuracy_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_classes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36maccuracy_score\u001B[0;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;31m# Compute accuracy for each possible representation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m     \u001B[0my_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0my_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"multilabel\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     82\u001B[0m     \u001B[0my_pred\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0marray\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mindicator\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m     \"\"\"\n\u001B[0;32m---> 84\u001B[0;31m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m     \u001B[0mtype_true\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[0mtype_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    330\u001B[0m     \u001B[0muniques\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    331\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 332\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m    333\u001B[0m             \u001B[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    334\u001B[0m             \u001B[0;34m%\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlengths\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [7532, 751]"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for data_module in [ng_data_module, ib_data_module, b_data_module]:\n",
    "    X = data_module.train_data\n",
    "    y = data_module.train_classes\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X, y)\n",
    "    pred = clf.predict(data_module.test_data)\n",
    "    print(\"RESULT:\", accuracy_score(data_module.test_classes, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "751"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ng_data_module.test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7532, 751]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-94-3270499be34f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mlrcv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mlrcv_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlrcv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"RESULT:\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_classes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlrcv_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36maccuracy_score\u001B[0;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;31m# Compute accuracy for each possible representation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m     \u001B[0my_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0my_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"multilabel\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     82\u001B[0m     \u001B[0my_pred\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0marray\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mindicator\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m     \"\"\"\n\u001B[0;32m---> 84\u001B[0;31m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m     \u001B[0mtype_true\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[0mtype_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    330\u001B[0m     \u001B[0muniques\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    331\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 332\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m    333\u001B[0m             \u001B[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    334\u001B[0m             \u001B[0;34m%\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlengths\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [7532, 751]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# for data_module in [ng_data_module, ib_data_module, b_data_module]:\n",
    "data_module = ng_data_module\n",
    "X = data_module.train_data\n",
    "y = data_module.train_classes\n",
    "lrcv = LogisticRegressionCV()\n",
    "lrcv.fit(X, y)\n",
    "lrcv_pred = lrcv.predict(data_module.test_data)\n",
    "print(\"RESULT:\", accuracy_score(data_module.test_classes, lrcv_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}